{"/blogs/forensics/":{"data":{"":" ℹ️ Note: Some posts are still in progress. Explanations or code may be updated. "},"title":"Forensics"},"/blogs/forensics/cbe-fundamentals/":{"data":{"":"","#":"","chaos-based-image-encryption#Chaos Based Image Encryption":"","creating-secure-chaos-based-systems#Creating Secure Chaos Based Systems":"","entropy-analysis#Entropy Analysis":"","external-references#External References":"Before diving deeper into the implementation and analysis of image fiel types, I would like to acknowledge Lazaros Moysis and his YouTube series on Chaos-Based Encryption. Youtube Channel: https://www.youtube.com/@lazarosmoysis5095\nEach section of this article will feature one of his videos, along with a detailed explanation of its content. The goal is to provide a more detailed breakdown of the topics he covers, as well as possible scripts or implementations he might be using.\nUnderstanding Image Functionality How it is represented To start understanding how an image is represented, the knowledge of a NxM matrix is needed.\n$$ A = \\begin{bmatrix} a_{ij} \\end{bmatrix} $$ $$ \\quad a_{ij} \\in \\mathbb{Z}, ; a_{ij} \\in [0, 255], ; i = 1, \\dots, N, ; j = 1, \\dots, M $$ Every integer in the interval [0,255] can be represented usinng 8 bits, following the fundamentals of number theory:\n$$ a_{ij} = a_{ij}^1 {{2^0}} + a_{ij}^2 {{2^1}} + a_{ij}^3 {{2^3}} + a_{ij}^4 {{2^4}} + a_{ij}^5 {{2^5}} + a_{ij}^6 {{2^6}} + a_{ij}^7 {{2^7}} + a_{ij}^8 {{2^8}} $$\nTherefore, image creation involves manipulating a matrix, processing each pixel bit by bit. The following is an example:\nWith a 4 pixel Image, it will follow the process:\nimport numpy as np imageData = np.array([[0, 85], [170, 255]], dtype=np.uint8) def extractBits(image): height, width = image.shape bitLayers = np.zeros((8, height, width), dtype=np.uint8) for bit in range(8): bitLayers[bit] = (image \u003e\u003e bit) \u0026 1 return bitLayers bitLayers = extractBits(imageData) for bit in range(8): print(f\"Layer {bit + 1}:\\n{bitLayers[bit]}\", end='\\n\\n') Output:\nLayer 1: [[0 1] [0 1]] Layer 2: [[0 0] [1 1]] Layer 3: [[0 1] [0 1]] Layer 4: [[0 0] [1 1]] Layer 5: [[0 1] [0 1]] Layer 6: [[0 0] [1 1]] Layer 7: [[0 1] [0 1]] Layer 8: [[0 0] [1 1]] For greater clarity, each layer can be compared to the positional values of bits in a binary representation.\n\u003e\u003e\u003e print(bin(0)) 0b0 \u003e\u003e\u003e print(bin(85)) 0b01010101 \u003e\u003e\u003e print(bin(170)) 0b10101010 \u003e\u003e\u003e print(bin(255)) 0b11111111 PD: In the layers the first number goes to the back, and the last to the front, so the number 0babcdefgh in layers will be hgfedcba\nRepresentation of Authentic Images And all of this applies only to a black-and-white image. When working with full RGB color, things become more complex due to the increased amount of data. As a fun fact, when compressing an image, what you are doing exactly is to reconstruct the image from levels 5-8, 6-8, usually, obtaining the last 3 bits.\nPython Script: RGB Process To apply in RGB images replace the 8 bits to 24 bits, diving each 8 block bits for Red Green and Blue colors.\nimport numpy as np imageData = np.array( [ [ # R G B [85, 170, 255], [255, 255, 255] ], [ [170, 85, 255], [0, 0, 0] ] ], dtype=np.uint8) def extractBitsRGB(image): height, width, channels = image.shape bitLayers = np.zeros((8, height, width, channels), dtype=np.uint8) for bit in range(8): for channel in range(3): bitLayers[bit, :, :, channel] = (image[:, :, channel] \u003e\u003e bit) \u0026 1 return bitLayers bitLayers = extractBitsRGB(imageData) # Mostrar los resultados for bit in range(8): print(f\"Red:\\n{bitLayers[bit][:, :, 0]}\",end='\\n\\n') print(f\"Green:\\n{bitLayers[bit][:, :, 1]}\",end='\\n\\n') print(f\"Blue:\\n{bitLayers[bit][:, :, 2]}\",end='\\n\\n') Once understood, the basics, we can proceed with the Chaos-Based-Image Encryption.\nChaos Based Image EncryptionWhy to choose Chaos-Based Encryption? Chaos-Based Encryption (CBE) are very sensitive with their seed, with a minimun change in the seed can cause a total diferent result, this can be very useful, to create dynamic keys or encrypted patterns with a low entropy. Making harder to decrypt with linear and diferencials attacks based on the correlations between input and output Mainly the CBE is used in multimedia content such as images, videos, audio and text, with a simple matemathical operations more than AES or RSA, can be run in a low cost hardware.\nFurthermore in the Differential Cryptanalysis on Chaotic Based Image Encryption Scheme article from Lee Kong Chian Faculty of Engineering and Science, Universiti Tunku Abdul Rahman, 43000 Kajang, Selangor, Malaysia mentioned in the NPCR and UACI cryptoanalysis tests says:\nThe rapid development of computer network technology allows widespread transmission of multimedia data such as images and videos over insecure communication channels.\u003e Therefore, a fast and secure image encryption method is deemed important to protect the multimedia data from being accessed by the unauthorized users. The traditional data encryption methods such as Data Encryption Standard (DES), Advanced Encryption Standard (AES) and International Data Encryption Algorithm (IDEA) are no longer suitable for image encryption due to the bulk data capacity and high data capacity. To overcome this drawback, different image encryption methods were proposed based on DNA [1,2], hash function [3], Substitution-box (S-box) [4] and chaotic maps [5–13].\nOn the other hand, it is true that traditionals methods like AES, RSA and ECC are well documented and standardized by organizations such us NIST. CBE being short of documentation complicating the implementation of such encryption. Furthermore in systems where is used the 32 bits may cause rounding errors (reducing security), if you configure it in a wrong way…\nThere can be specific attacks for these chaotic algorithms, such us: https://rac.es/ficheros/doc/01213.pdf or the mentioned before: Differential Attacks in CBE\ndef fun(x9,r,n): x = np.zeros(n) x[0] = x0 for i in range(1, n): x[i] = r * x[i-1] * (1 - x[i-1]) return x Differences Compared to Standard Cryptography Something to keep in mind is the different technicalities between a chaotic system and a cryptographic algorithm.\ngraph TD\rsubgraph Crypto_Algo [Cryptographic algorithms]\rCA1[\"Cryptographic algorithms\"]\rCA2[\"Phase space: finite set of integers\"]\rCA3[\"Rounds\"]\rCA4[\"Key\"]\rCA5[\"Diffusion\"]\rCA6[\"Security and performance\"]\rCA1 --\u003e CA2 --\u003e CA3 --\u003e CA4 --\u003e CA5 --\u003e CA6\rend\rsubgraph Chaotic_Sys [Chaotic systems]\rCS1[\"Chaotic systems\"]\rCS2[\"Phase space: (sub)set of real numbers\"]\rCS3[\"Iterations\"]\rCS4[\"Parameters\"]\rCS5[\"Sensitivity to initial conditions\"]\rCS6[\"Unpredictability\"]\rCS1 --\u003e CS2 --\u003e CS3 --\u003e CS4 --\u003e CS5 --\u003e CS6\rend Security Testing and Image AnalysisBelow is a detailed explanation of several techniques used to assess the security of a chaotic system\nHistogram Analysis There are two mainly encryption methods with CBE:\nPermutation = Shuffling the pixels of the image Substitution = Changing the values of the pixel images By reading this, you can think…\nIs pixel permutation enough? This is a very clear and brief question about the comparation between shuffling and encryption, and the fast answer is: no. Buy why is it not enought? Well, permutation only changes the positions of pixels, meaning that their values still the same. Furthermore permutation is inherently deterministic and reversible.\nReading and investigating I found the following conclusion:\n$$ \\forall a, b \\in S,, \\pi(a) = \\pi(b) \\Rightarrow a = b $$ $$ \\forall y \\in S,, \\exists x \\in S ; \\pi(x) = y $$\nA permutation is a bijective mapping, a one-to-one and onto function, from a set to itself. So the set of all permutations of n elemnts forms the symmetric group S. Since permutatinos are bijections, we can conclude they are invertible, being:\n$$ \\pi^{-1}(\\pi(x)) = x $$ So the reversibility of permutations come from the permutations invertibles bijections from the group theory.\nThe group theory is the studies of algebraic structures know as groups. And says that a group is a set of elements and an operation that meets 4 other conditions:\n$\\text{It is closed if a,b} \\in G \\text{, then }ab \\in G.$ $\\text{It has an identity, if there is an } e \\in G \\text{ such that for all }a \\in G : ea = ae = a.$ $\\text{Every elemnt has an inverse for all } a \\in G \\text{ there is a } b \\in G \\text{ suich that } ab = e.$ $\\text{Its operation is associative for all }a,b,c \\in G : (ab)c =a(bc).$ If you want to learn more about group theory watch: https://www.youtube.com/watch?v=IRZK3Dq0OZM.\nTo conclude this section it is demostrated that permutation is a symmetric group and it can be inverted, being more insecure than encryption.\n‎\nFor checking, one part of the security of the encryption we can use the Histogram, which decipts the distributions of greyscale values. Images depicting information will have a non-uniform histogram.\nThe histogram of the original image and the permutated/shuffled iamge are the same while the substituted image are diferent, usually with a smaller variance…\nIf you are treating with non-gray images, such us RBG formats, you will see a histogram for each color, here an example of original image in RGB and substituted/encrypted image in RGB:\nPixel Correlation Analysis Another method for testing the security is the Correlation, measuring similarity between adjacent pixels.\nAdjacent Pixel refers to the pixel points in an image that are positioned next to each other. The correlation between adjacent pixels is used to evaluate the encryption effect, with original images showing strong correlations and encrypted images displaying little to no correlation among neighboring pixel points.\nIt can be used to asses the encryption effect, there are 4 main formulas to calculares this correlation between neigboring pixels:\nE(x) - Expected value (Mean) $$ E(x) = \\frac{1}{N} \\sum_{i=1}^{N} x_i $$ This formula represents the average value of the random variable x, with this information we are able to know the average color and brightness of the pixel, and can help us to detect if there are posibilities of a LSB (Least Significant Bits) stego method. E(x) is used in statistical prediction models and in some classification algorithms to normalize additional data for multimedia file types.\nIt gives us an idea of the central value of the data. In images, if the average is high, the image is generally bright, else the image is dark. To detect the diference we need to follow this simple formula:\n$$ \\Delta E = E(x_{\\text{modified}}) - E(x_{\\text{original}}) $$\nScript in Sage (Python Interpreter) Manual Now we are going to recreate the formula in sage, for this we need to understand what is x and N:\nx represents the intensity of value of each pixel N is the amount of pixels in the image (width × height) def E(x): N = len(x) return sum(x) / N OpenVC with Numpy Anyways we have public modules with this imported… Using OpenVC and Numpy we can do the same function:\nimport cv2 import numpy as np image = cv2.imread(\"image.png\", cv2.IMREAD_GRAYSCALE) meanValue = np.mean(image) print(meanValue) Type 1 | Spatial Autocorrelation Example Okay, perfect for the moment, but how we can use it, only having the suspicious file we can calculate the diference we mention before: $$ \\Delta E = E(x_{\\text{modificado}}) - E(x_{\\text{original}}) $$ I will use the implementation of OpenVC and Numpy, but you can try to use the manual one:\nimport cv2 import numpy as np image = cv2.imread(\"image.png\", cv2.IMREAD_GRAYSCALE) diffX = np.abs(image[:, 1:] - image[:, :-1]) meanX = np.mean(diffX) diffY = np.abs(image[1:, :] - image[:-1, :]) meanY = np.mean(diffY) print(f\"Variantion axis X: {meanX}\") print(f\"Variantion axis Y: {meanY}\") Output:\nVariantion axis X: 96.24803571428572\rVariantion axis Y: 90.30474206349206 Comparation of result To check if it is a suspicious variation we need to compare with normal images, once we have a few examples we run this code, if Z-Score is between [-2, 2] we can consider a normal output, otherwise the image could be manipulated\nimport numpy as np # Normal variances in images variancesX = [95, 98, 100, 96, 92, 94, 99, 97, 101, 93] variancesY = [90, 89, 88, 92, 94, 91, 93, 87, 95, 90] meanX, stdX = np.mean(variancesX), np.std(variancesX) meanY, stdY = np.mean(variancesY), np.std(variancesY) varX = 96.24803571428572 varY = 90.30474206349206 ZscoreX = (varX - meanX) / stdX ZscoreY = (varY - meanY) / stdY print(f\"Z-score X: {ZscoreX}\") print(f\"Z-score Y: {ZscoreY}\") Type 2 | Histogram Analysis This method is simpler than the Spatial Autocorrelation but is less accurate, we create an Histogram taking the values of the pixeles (0-255) and with matplot we search for any peak/beak in the image…\nimport matplotlib.pyplot as plt import cv2 image = cv2.imread(\"mia.jpg\", cv2.IMREAD_GRAYSCALE) hist = cv2.calcHist([image], [0], None, [256], [0,256]) plt.plot(hist) plt.title(\"Histogram Intensity\") plt.xlabel(\"Intensity value (0-255)\") plt.ylabel(\"Frequency\") plt.show() Here are the results of two examples, honestly I don’t use and I don’t recomend anyone this method, but is good to know about it:\nType 3 | Local Average Analysis import cv2 import numpy as np import matplotlib.pyplot as plt image = cv2.imread(\"uno.jpg\", cv2.IMREAD_ANYCOLOR) if len(image.shape) == 3: image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) block_size = 8 h, w = image.shape means = [] for i in range(0, h, block_size): for j in range(0, w, block_size): block = image[i:i+block_size, j:j+block_size] means.append(np.mean(block)) plt.hist(means, bins=50, color='blue', alpha=0.7) plt.title(\"Distribución de Medias por Bloques\") plt.xlabel(\"Media del Bloque\") plt.ylabel(\"Frecuencia\") plt.show() We can detect the bright of each range of pixels with their frequency…\nBut anyways, the exhaustive analysis come in the followings formulas.\nD(x) - Variance $$ D(x) = \\frac{1}{N} \\sum_{i=1}^{N} (x_i - E(x))^2 $$\nFull formula (Integration of Expected value): $$ D(x) = \\frac{1}{N} \\sum_{i=1}^{N} (x_i - (\\frac{1}{N} \\sum_{i=1}^{N} x_i,))^2 $$ The variance trys to explain how far the values of a variable are from their expected mean. In terms of images, it shows us the intensity values of each pixel and its vary. This variance is mainly calculated in this part of the formula, inside the summation:\n$$ (x_i - E(x))^2 $$ Being x the value of the pixel and E(x) the central value of the image. It is squared to avoid negative numbers, in case it may occur.\nHow to interpret the results (Theory) It may be a high variance or a low one, here a poor definition and why it may happen.\nHigh Variance: When the values are widely dispersed from the average, can means a possible manipulation in the pixels, but can be a false flag, considering the following cases:\nHigh detailed image High color contrast Low Variance: Usually in monochrome images where the pixels are closely to the average value, meaning there is no alteration in the pixels, it also can occurs in:\nBlurred image Natural images, which follows a pattern Script in Sage Manual from ExpectedValue import E def D(x): N = len(x) def squareDIF(): for xi in x: yield (xi - E(x))**2 return sum(squareDIF()) / N For non-experience python programmers, the funcion squareDIF() using yield will return an array, known as *args, with the values of the summation, using this to avoid a oneliner such us:\nreturn sum((xi - E(x))** 2 for xi in x) / N But as yield can cause a call overhead, we will use list comprehensions, for more optimization:\nimport cv2 def E(x): return sum(x) / len(x) def D(x): N = len(x) return sum((xi - E(x)) ** 2 for xi in x) / N def readIM(file): img = cv2.imread(file, cv2.IMREAD_ANYCOLOR) if img is None: raise ValueError(\"File not found\") return img.flatten().tolist() data = readIM('uno.jpg') print(\"Variance:\", D(data)) Using this example we will obtain the following output:\nVariance: 4225.138798415301 OpenVC with Numpy import numpy as np import cv2 image = cv2.imread(\"uno.jpg\", cv2.IMREAD_ANYCOLOR) variance = np.var(image) print(\"Variance:\", variance) As output we will get:\nVariance: 4225.138798416118 Interpret results (Practice) As we can see both codes give us the same output with an only difference of: $8.17 \\times 10^{-13}$. As we are here to learning, we are going to compare how much time spend each program.\nWith the manual process:\nVariance: 4225.138798415301\rExecution Time: 0.142820 seconds With the modules process:\nVariance: 4225.138798416118\rExecution Time: 0.008577 seconds We can see, of course, the computer process of the numpy library is much faster than the manual one… so it is not effective as the Expected Value (mean).\nI want to remember that with this information we are not able to get a 100% acurrate rate of knowing is an image suffers from LBS but can helps us to understand future advanced stego tools.\ncov(x,y) - Covariance (Population Covariance) $$ \\operatorname{cov}(x, y) = \\frac{1}{N} \\sum_{i=1}^{N} (x_i - E(x))(y_i - E(y)) $$\nFull formula (Integration of Expected value): $$ \\operatorname{cov}(x, y) = \\frac{1}{N} \\sum_{i=1}^{N} (x_i - (\\frac{1}{N} \\sum_{i=1}^{N} x_i))(y_i - (\\frac{1}{N} \\sum_{i=1}^{N} y_i)) $$\nCovariance is the next level of Variance formula, where measures the relationship between two variables, usually horizontal and vertical pixels, showing how the vary together. There can be 3 types of results applying this formula:\nPositive Covariance - Direct relationship Negative Covariance - Inverse relationship Near Zero Covariance - Null relationship This is a long and almost infinite content with a lot of diferent ways of calculating, but we are mainly focussed in the saga of videos, but here two usefulls reports to read:\nhttps://www.researchgate.net/publication/266333755_EMBEDDING_INFORMATION_IN_DCT_COEFFICIENTS_BASED_ON_AVERAGE_COVARIANCE/fulltext/54aea2820cf29661a3d39ee4/EMBEDDING-INFORMATION-IN-DCT-COEFFICIENTS-BASED-ON-AVERAGE-COVARIANCE.pdf https://hal.science/hal-02165866v1/document When we talk about the covarianze of images, we focus on the pattern of change of two variables simultaneosly. This helps us to understand the differencies between satellite images in unlike bands, or the R and G channel of an RGB image…\nTo be honest, this a inmense and almost infinite world but as I would like this study to come to light someday, I will not go much deeper into these topic… since it is only an uncertain study to verify whether or not there is considered steganography, and we are not in the third video of twelve… (If you want to go deeper please contact me and we can study and understand it better)\nScript in Sage from ExpectedValue import E def cov(x,y): N = len(x) r = 0 for i in range(N): r += (x[i] - E(x)) * (y[i] - E(y)) return (1 / N) * r cov(x,y) - Sampling covariance This is also a covariance but used for a fraction of the image, the formula we have seen is if the input data, the image, is the raw one, without modifications or trimming. If we have change the sample size the Sampling covariance will be more exactly that the Population. The formula varies in the way we write the denominator, we have seen: N but for this new type of covariance we will subtract one.\n$$ \\operatorname{cov}(x, y) = \\frac{1}{N-1} \\sum_{i=1}^{N} (x_i - E(x))(y_i - E(y)) $$\nBoth, the Latex formula and the Sage script, are almost the same.\nfrom ExpectedValue import E def cov(x,y): N = len(x) r = 0 for i in range(N): r += (x[i] - E(x)) * (y[i] - E(y)) return (1 / (N - 1)) * r γ(x,y) - Pearson correlation coefficient $$ \\gamma(x, y) = \\frac{\\operatorname{cov}(x, y)}{\\sqrt{D(x)} \\sqrt{D(y)}} $$\nFull formula (Integration of Variance + Expected value + Covariance): $$ \\gamma(x, y) = \\frac{\\frac{1}{N} \\sum_{i=1}^{N} (x_i - (\\frac{1}{N} \\sum_{i=1}^{N} x_i))(y_i - (\\frac{1}{N} \\sum_{i=1}^{N} y_i))}{\\sqrt{(\\frac{1}{N} \\sum_{i=1}^{N} (x_i - (\\frac{1}{N} \\sum_{i=1}^{N} x_i))^2)} \\sqrt{(\\frac{1}{N} \\sum_{i=1}^{N} (x_i - (\\frac{1}{N} \\sum_{i=1}^{N} y_i))^2)}} $$\nAlso this formula can be spotted in google as: $$ r = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum (x_i - \\bar{x})^2 \\sum (y_i - \\bar{y})^2}} $$\nPearson’s correlation coefficient is a statistical measure to quantify the linear relationship between two associated pixels. Used for the detection of possible modifications in an image caused by the insertion of additional information.\nIn the formula, in the numberer, the function cov(x,y) is a population covariance without normalization; and in the denominator will be the standard deviations without normalizing. But if you want to take a sample or a small fraction of the image you will need to normalizate both (but at the end of the day… there will be no changes, because the denominator where the normalization is located will be simplified), numberer and denominator, the numberer was mention before but the variance formula will result in:\n$$ D(x) = \\frac{1}{N-1} \\sum_{i=1}^{N} (x_i - E(x))^2 $$ By writting down the “Sampling Pearson Correlation Coefficient” this big and complex formula will appear.\n$$ \\gamma(x, y) = \\frac{\\frac{1}{N-1} \\sum_{i=1}^{N} (x_i - (\\frac{1}{N-1} \\sum_{i=1}^{N} x_i))(y_i - (\\frac{1}{N-1} \\sum_{i=1}^{N} y_i))}{\\sqrt{(\\frac{1}{N-1} \\sum_{i=1}^{N} (x_i - (\\frac{1}{N} \\sum_{i=1}^{N} x_i))^2)} \\sqrt{(\\frac{1}{N-1} \\sum_{i=1}^{N} (x_i - (\\frac{1}{N} \\sum_{i=1}^{N} y_i))^2)}} $$ Before simplifying the formula I want to mention that the standarization/normalization is the action of subtracting one to the amount of pixels in the (piece of the) image. If you have paid attention you will see that the expected value is not normalized, but why the rest of them are and this one is not?\nThe expected value (mean) is calculated by dividing the sum of the values by N (or by N if it is the population), and is not “normalized” in the same way. This is because in the Pearson Correlation or in Sampling Pearson Correlation the denominators will simplify, so they need to be in an equal status to be able to work correctly.\nAfter that, we continue with the simplyfied formula. Starting with a variable change will be performed, instead of calling the sumatory of the expected value we are going to name it: \\bar{x} and \\bar{y}\n$$ \\bar{x} = E(x) = \\frac{1}{N} \\sum_{i=1}^{N} x_i $$ $$ \\bar{y} = E(y) = \\frac{1}{N} \\sum_{i=1}^{N} y_{i} $$ Then canceling all denominator, that’s why you need to have Covariance and Variance in the same type, or normalizated/sampled or not, you will found the exact formula found in Google. $$ \\gamma(x, y) = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum (x_i - \\bar{x})^2 , \\sum (y_i - \\bar{y})^2}} $$ If we name properly the formula we will have $$ \\gamma(x, y) = \\frac{\\operatorname{cov}(x, y)}{\\sqrt{D(x)} \\sqrt{D(y)}} $$\nScript in Sage from ExpectedValue import E from Variance import D from Covariance import cov def r(x,y): numberer = cov(x,y) denominator = D(x) * D(y) return numberer / denominator Interpretting results The outcome of this formula is inside the range of -1 and 1, depending on the proximity of each value: {-1, 0, 1}: $$ \\gamma(x,y) \\approx 1: \\text{The relation between the pixels is strong and in principle does not suffer from manipulation} $$ $$ 1 \u003e \\gamma(x,y) \\ge 0.1: \\text{High probability that the image have been manipulated. If } \\gamma = 0 \\text{ there are not correlation between pixels from } x \\text{ and } y. $$ $$ \\gamma \u003c 0: \\text{The pixels are inversely proportional, also high probability of being manipulated.} $$ We have finish the Pixel Correlation Analysis, this is more focussed on how images work, but can help us in the detection of steganography, but I repeat my-self again, IT IS NOT ACCURATE.\nTesting for Security As all we have seen, we can study the correlation of pixels without a problem, having the comparation of 3 images:\nPlaintext Shuffled Encrypted With their correlation:\nEntropy Analysis Let us begin with the precise definition of entropy:\nComputting entropy:\nIn computing, entropy is the randomness collected by an operating system or application for use in cryptography or other uses that require random data. This randomness is often collected from hardware sources, either pre-existing ones such as mouse movements or specially provided randomness generators.\nInformation theory entropy\nIn information theory, entropy is a measure of the uncertainty associated with a random variable. The term by itself in this context usually refers to the Shannon entropy, which quantifies, in the sense of an expected value, the information contained in a message, usually in units such as bits. Equivalently, the Shannon entropy is a measure of the average information content one is missing when one does not know the value of the random variable\nThe conclusion is that the enyropy is the amount of informatino and unpredictability/uncertainty present in an image. The highest theoretical value of the entropy is 8, the higher entropy denotes high unpredictability/uncertainity pixel correlation, being the higher, the safer. To continue a detailed explanation of the formula, with a main source of the survey of Computational entropy of Harvard.\nEntropy formulas (Unidimensional) $$ E = - \\sum_{2i=0}^{2^L - 1} p_i \\log_2 p_i $$\nIt mentions the measures of the entropy when X is a discrete random variable, the same thing that we are studying:\n$$ H(X) = \\mathbb{E}_{x \\leftarrow X} \\left[ \\log_2 \\left( \\frac{1}{\\Pr[X = x]} \\right) \\right] $$ At a glance, it seems to be a completed difference formula, but it is the same formula, but the implementation of some variable change are necesary, the expectation can be written as a sum over all possible values of x (in X).\n$$ \\mathbb{E_{x \\leftarrow X}} = \\sum_{ x \\in \\mathcal{X} } Pr[X = x] $$\nIn a correct notation. which will be not used, is writed as,\n$$ \\mathbb{E}|X| = \\sum_{x \\in \\mathcal{X}} x \\times Pr[X = x] $$\nPr[X = x] is the probability of the molecular proposition X has the value of the atomic proposition x.\n‎\nAfter the variable chage, it will be a result of:\n$$ H(X) = \\sum_{x \\in \\mathcal{X}} {\\Pr[X = x]} \\left[ \\log_2 \\left( \\frac{1}{\\Pr[X = x]} \\right) \\right] $$\nFor convenience all possible values of x will be named as p, and the possible value of x equals i\n$$ p_{i} = {\\Pr[X = i]} $$\n$$ H(X) = \\sum_{i} {p_{i}} \\left[ \\log_2 \\left( \\frac{1}{p_{i}} \\right) \\right] $$\nBy properties of logarithms can be:\n$$ H(X) = \\sum_{i} {p_{i}} \\log_2 \\left( \\frac{1}{p_{i}} \\right) = \\sum_{i}{p_{1}} \\log_2 \\left( {p_{i}} \\right)^{-1} = -\\sum_{i}p_{i} \\log_{2} p_{i} $$ Finally, considering the value of X are: i = 0,1,...,2L-1, where L is the number of possible binary values, with two possibles results, (1 and 0), the number of combinations could be calculated as: 2^L.\nDemostrating the correlation of both formulas. $$ E = - \\sum_{2i=0}^{2^L - 1} p_i \\log_2 p_i $$ Now that the relationship is mentioned the following formulas can be understood. But before, the same formula scripped in Sagemath.\nSage Script from math import log def Entropy(L:list,E:float=0.0) -\u003e float: for p in L: if p \u003e 0: E -= p*log2(p) return E min-entropy | Minimun Formula $$ H_{\\infty}(X) = min_{x}\\left[ \\log_{2}\\left( \\frac{1}{Pr[X=x]} \\right) \\right] = \\log_{2}\\left( \\frac{1}{max_{x} Pr[X=x]} \\right) = - \\log_{2} (max_{x} Pr[X=x]) $$\nSage Script from math import log2 def H_Inf(X:list) -\u003e float: Pmax = max(X) return -log2(Pmax) ‎\nmax-entropy | Maximun Also know as the Entropy of Hartley, uses the set-builder notation which obtains only the non-negativa values from the source predicate.\nFormula $$ H_{0}(X) = \\log |{x : Pr[X=x] \u003e 0}| $$\nSage Script from math import log2 def H_0(X:list) -\u003e float: x=0.0 for xi in X: if xi \u003e 0: x+=1 return log2(x) if x != 0 else 0.0 Unimensional review H(X) measures the average number of bits of randomness in X, while H_{infty}(X) and H_{0}(X) are worst-case lower and upper bounds on H(X). Indeed, we have:\n$$ H_{\\infty}(X) \\le H(x) \\le H_{0}(X) $$ $$ \\text{with equalitity if and only if X is uniform on } {x : Pr[X=x] \u003e 0} \\text{ ; that is, X is a flat distribution} $$\nBut… all of this only for an unidimensional array, in terms of images, only the horizontal axis, so now, the full image, a bidimensional Shannon \u0026 Hartley Entropy will be shown. Before entering dellate, it is possible to flatten the image:\n\u003e\u003e\u003e import numpy as np \u003e\u003e\u003e image = np.random.random((3,3)) \u003e\u003e\u003e print(image) [[0.10002498 0.83730832 0.26422208] [0.42196167 0.34551549 0.68976181] [0.08653794 0.23869748 0.69132533]] \u003e\u003e\u003e flattenImage = image.flatten() \u003e\u003e\u003e print(flattenImage) [0.10002498 0.83730832 0.26422208 0.42196167 0.34551549 0.68976181 0.08653794 0.23869748 0.69132533] If the array needs to be flattened and they not come from numpy the following function can be used:\nflattenImage = [pixel for row in p for pixel in row] The results will be the same, a very good option to avoid complications. Also, this is only for greyscale images, for RGB scale, it is necesary to split the channels.\ndef splitI(image): Rc = [] Gc = [] Bc = [] for row in image: Rr = [] Gr = [] B_row = [] for pixel in row: R, G, B = pixel R_row.append(R) G_row.append(G) B_row.append(B) R_channel.append(R_row) G_channel.append(G_row) B_channel.append(B_row) return R_channel, G_channel, B_channel imageRGB = [[(),(),(),()],[(),(),(),()],[(),(),(),()]] R,G,B = splitI(image_color) Bidimensional Entropy Formulas The main formula does not change in its mathematical principles; only the way we implement the code varies.\nfrom math import log def Entropy(L:list,E:float=0.0) -\u003e float: for row in L: for p in row: if p \u003e 0: E -= p*log2(p) return E Bidimensional min-entropy Formula $$ H_{\\infty}(I) = min_{(x,y)}\\left[ \\log_{2}\\left( \\frac{1}{Pr[I(x,y)]} \\right) \\right] = \\log_{2}\\left( \\frac{1}{max_{(x,y)} Pr[I(x,y)]} \\right) = - \\log_{2} (max_{(x,y)} Pr[I(x,y)]) $$\nSage Script To simplify the problem, the use of numpy will be applied.\nimport numpy as np from math import log2 def H_inf(I:list) -\u003e float: pMax = np.max(I) return -log2(pMax) Remember that to use np.max() requires an np.array.\nBidimensional max-entropy Formula $$ H_{0}(I) = \\log |{(x,y) : I(x,y) \u003e 0}| $$\nSage Script import numpy as np from math import log2 def H_0(I:list) -\u003e float: c = np.count_nonzero(I \u003e0) return log2(c) if c != 0 else 0.0 As the same as min-entropy it is required a numy array, if not use: flattenImage = [pixel for row in p for pixel in row]\nTesting for Security While using this scripts, setting the value of L as (8 bytes) the maximun value will be 8, like the following examples:\nMaybe the image you are using could not be the same highest theoretical value, thats why the max-entropy function was explained. Before the survey is continued, I recommend take a look to the following pdf I have already mentioned, it is very good resource for learning Entropy:\nhttps://salil.seas.harvard.edu/sites/g/files/omnuum4266/files/salil/files/acm-publishedversion.pdf Local Entropy If you noticed, the Entroy has a little problem, the data “Plaintext” and “Shuffled”, have the same entropy level, causing a confusion…. That’s why local entropy is created. Consider a collection of non-overlapping blocks in a image, compute the entropy of each block and calculate the avegrage entropy of these entropies, to obtain the local entropy. You can consider N number of blocks with MxM size pixels.\n$$ \\lim_{ N \\to \\infty } = \\frac{1}{N} \\sum_{i=1}^{N} H(B_{i}) = H(X) $$\nFurthermore, by the CLT (Central Limit Theorem), the estimation error usually decays as follows:\n$$ |H(X) - \\hat{H}_{N}| \\propto \\frac{1}{\\sqrt{ N }} $$\nHere a brief comparation:\nPython Script for Blocks import numpy as np import cv2 import random from typing import List def nonOverlappingBlocks(image: np.ndarray, blockSize: int, numberBlocks: int) -\u003e List[np.ndarray]: height, width = image.shape[:2] blocks = [] usedPositions = set() if blockSize \u003e min(height, width): raise ValueError(f\"{blockSize} \u003e (greater than) {height}x{width} (Image shape)\") maxAttempts = 100 attempts = 0 while len(blocks) \u003c numberBlocks and attempts \u003c maxAttempts: x = random.randint(0, width - blockSize) y = random.randint(0, height - blockSize) overlaps = False for (used_x, used_y, used_size) in usedPositions: if not (x + blockSize \u003c= used_x or x \u003e= used_x + used_size or y + blockSize \u003c= used_y or y \u003e= used_y + used_size): overlaps = True break if not overlaps: block = image[y:y+blockSize, x:x+blockSize] blocks.append(block) usedPositions.add((x, y, blockSize)) else: attempts += 1 if len(blocks) \u003c numberBlocks: print(f\"Maximun non-overlapped blocks: {len(usedPositions)}\") return blocks Use example:\nif __name__ == \"__main__\": imagePath = \"image.png\" image = cv2.imread(imagePath) if image is None: raise FileNotFoundError(f\"File not found: {imagePath}\") blockSize = 32 numberBlocks = 10 blocks = nonOverlappingBlocks(image, blockSize, numberBlocks) for block in blocks: print(block) NPCR \u0026 UACI Cryptanalysis As It is mentioned in one of the first sections of this post, Chaos Based Encryption is typically prone to suffer cryptographic differentials attacks such as:\nDifferential and Chosen-Plaintext Attacks (CPA) Boomerang y Rectangle Attacks Differential-Linear Cryptanalysis NPCR/UACI: Chosen-Plaintext Differential in encrypted images Differential Known-Plaintext Attacks in Chaotic PRBS In this section the NPCR/UACI attacks will be spoken, anyways If it is precise a further explanation check the following PDF: https://arxiv.org/pdf/1910.11679, due you are reading a brief explanation of some important part of CBE, in the article mentioned you will find some conventional attacks e.g., chosen plaintext attack, known plaintext attack, and arguing the vulnerable encryption scheme for embedded systems based on continuous third-order hyperbolic sine chaotic system proposed by Z. Lin et al. in A novel fast image encryption algorithm for embedded systems.. Using:\n$$ \\ddot{x} + 0.75\\dot{x} + x + 1.2 \\times 10^{-6} \\cdot x \\sinh\\left(\\frac{\\dot{x}}{0.026}\\right) = 0 $$\nBoth tests are selected to measure the resistance of a proposed cryptosystem against the differential attacks introduced by Eli Biham and Adi Shamir in differential cryptanalysis of DES-like cryptosystems. Journal of CRYPTOLOGY, 4(1):3–72, 1991.\nNumber of Pixels Change Rate - NPCR NPCR measures the percentage of pixels variations between two encrypted images when their corresponding cleartext images differ with only one pixel, with the purpose of evaluates the sensitive of the encryption system to small changes in the plain image. The higher the NPCR, the more noticeable the difference is proportionally, meaning the CBE systems works correctly.\nKnowing this we can go into the formula:\n$$ NPCR = \\frac{\\sum_{i,j}D(i,j)}{M \\times N} \\times 100% $$ Where:\n$D(i,j) = \\begin{cases} 1 \u0026 \\text{if } C_1(i,j) \\neq C_2(i,j) \\\\ 0 \u0026 \\text{if } C_1(i,j) = C_2(i,j) \\end{cases} \\text{ ; also }D(i,j) \\text{ is the binary difference indicator and not the variance function of Pixel Correlation Analysis}$ $C_{1} \\text{ and } C_{2} \\text{ are the two encrypted images}$ $M \\times N \\text{ is the image dimensions}$ It is suposed to return a ~\u003e99.5% or higher value to being a normal Chaos Based Encryption, we can know with the following Sage Script:\ndef NPCR(img1,img2): M = len(img1) N = len(img1[0]) if len(img2) != M or any(len(row) != N for row in img2): raise ValueError(\"Images dimensions do not coincide\") variation = 0 for x in range(M): for y in range(N): if img1[x][y] != img2[x][y]: variation+=1 return (variation / M*N) * 100 It is also possible to apply the Pillow module:\nfrom PIL import image import numpy as np def NPCR(imgPath1, imgPath2): img1 = Image.open(image_path1).convert('L') img2 = Image.open(image_path2).convert('L') arr1 = np.array(img1) arr2 = np.array(img2) if arr1.shape != arr2.shape: raise ValueError(\"Images dimensions do not coincide\") M, N = arr1.shape D = arr1 != arr2 variation = np.sum(D) return (variation / M*N) * 100 Unified Average Changing Intensity - UACI UACI is designed to test the number of mean intesities modified between two encrypted images (commonly used in interferograms), when the difference between the plaintext image is subtle the optimal value of UACI is ~33.46%, in other words UACI quantifies how much the variation of the pixel, which reflects the algorithm’s abilioty to spread differences uniformly across the image.\nAuthor anotation: While doing this part of the post I started thinking what was the relationship of the UACI tests with the Chaos Based Image, If you are reading this I am going to refresh you the meaning of a chaotic system, being the brutal variantion of encryption with a small differ in the seed/key/source of the system/algorithm. This tests, also for NPCR, evaluate the sensitive of the cypher at differentials attacks.* $$ UACI = \\frac{1}{M \\times N} \\sum_{i,j}\\frac{|C_{1}(i,j)-C_{2}(i,j)|}{255} \\times 100% $$ Where:\n$C_{1} \\text{ and } C_{2} \\text{ are the two encrypted images}$ $M \\times N \\text{ is the image dimensions}$ As we mention earlier the perfect percent for this function is 33,46%, that indicates that the cryptographic algorithm and the chaos system is secure. To calculate the UACI from two cipher images use the following code:\ndef UACI(img1, img2): M = len(img1) N = len(img1[0]) if len(img2) != M or any(len(row) != N for row in img2): raise ValueError(\"Images dimensions do not coincide\") variation:float = 0 for x in range(M): for y in range(N): diff = abs(img1[x][y] - img2[x][y]) variation += diff / 255 return (variation / M*N) * 100 Hamming Distance - HD To conclude this anti-plain-text sensitivity attack sention I want to talk about the not mention Hamming Distance function from Mousa Farajallah in Chaos-based crypto and joint crypto-compression systems for images and videos.\n$$ HD(C_{1}, C_{2}) = \\frac{1}{|Ib|} \\sum^{|Ib|}{K-1} (C{1}(K) \\oplus C_{2}(K)) $$ Where:\n$|Ib| = L \\times C \\times P \\times 8$, is the size of thge image in bits $L$ is the number of rows in the image, also called $lines$ $C$ is the number of columns in the image $P$ is the number of color planes channels The optimun HD value is 50%. A good bloc cipher should produce an HD close to 50%. “Probability of bit changes, which means that a one bit difference in plain-image will make every bit of the corresponding cipher-image change with a probability of half” mentions Xingyuan Wang, Dapeng Luan, and Xuemei Bao. in Cryptanalysis of an image en-cryption algorithm using chebyshev generator. Digital Signal Processing, 25:244–247, 2014\nTherefore, the plain-text sensitivity attack would become a useless attacking method.\nTo tests it use:\ndef HD(C1, C2): L = len(C1) C = len(C1[0]) if isinstance(C1[0][0], int): P = 1 else: P = len(C1[0][0]) totaBits = L * C * P * 8 variance = 0 for x in range(L): for y in range(C): if P == 1: px1 = C1[x][y] px2 = C2[x][y] xored = px1 ^ px2 variance += bin(xor_result).count('1') else: for z in range(P): px1 = C1[x][y][k] px2 = C2[x][y][k] xored = px1 ^ px2 variance += bin(xor_result).count('1') return (variance / totalBits) * 100 Creating Secure Chaos Based Systems The next step is yours. In this paper we have seen what is a Chaotic System, what are they used for, some validity checking for being secure, but how to create one? What properties needs a algorithm to be consider a system? In this section we will get in-depth with some complex (at least for me) mathematical concepts.\nLyapunov exponent First of all, we should mention Lyapunov exponent, which measures the rate at which an infinitesimally small distance between two initially close states grows over time, in other words, it measures exponential divergence.\nTo understand better the exponent think in two small balls, in the top of a hill, both are nearly the same distance apart, if the hill is smooth, flat, without any rocks you could calculate normaly the trajectory and predict that both will stop in the same space (being the initial space insignificant). This is a common dinamic system.\nOnly, in real life there are rocks, craters, around all the hill, making detours to the balls. Now, its harder to think that each ball will be nearly when they stop, this is how chaotic system works.\nFormula Thus, the Lyapunov exponent is formed as:\n$$ F^{t}(x_{0} + \\varepsilon) - F^{t}(x_{0}) \\approx \\varepsilon e^{\\lambda t} $$\nBeing $\\lambda$ the Lyapunov exponent. The left side is the distance between two initially close states after lost steps, and the right side is the assumption that the distance grows exponentially with time. $\\lambda$ is measured by a long period time ideally $t \\to \\infty$. Also, $\\epsilon$ are the rocks, craters with a minimun value $\\epsilon « 1$ or $\\epsilon = 10^{-6}$.\nIf $\\lambda \u003c 0$, the smalls distances are similar not consider a chaotic system. To clear the exponent follow:\n$$ e^{\\lambda t} \\approx \\frac{F^{t}(x_{0} + \\varepsilon) - F^{t}(x_{0})}{\\epsilon} $$\nBeing $\\delta(t) = F^{t}(x_{0} + \\varepsilon) - F^{t}(x_{0})$\n$$ \\lambda = \\frac{1}{t} \\ln ( \\frac{\\delta(t)}{\\epsilon}) $$\nLastly, the limits:\n$$ \\lambda = \\lim_{ t \\to \\infty ,\\epsilon \\to 0 } \\frac{1}{t} \\ln ( \\frac{\\delta(t)}{\\epsilon}) $$\nOnce this is understood, let’s take the following POSSIBLE chaotic system: $f(x) = k \\times x \\times (x-1)$ and the linear map: $g(x) = x \\times k$, where $k \\text{ is cte}$ in both cases.\nTo calculate the exponent, use the following sage function:\nimport numpy as np def lyapunov(mapFunction, x0, eps, idx, discard=100): x=x0 xPert = x0 + eps lyap = 0.0 for i in range(idx): x = mapFunction(x) xPert = mapFunction(xPert) delta = abs(xPert - x) xPert = x + eps * (xPert - x) / delta if i \u003e= discard: lyap += np.log(delta / eps) ei = idx - discard return (lyap / ei) def f(k): return lambda x: k * x * (1 - x) def g(k): return lambda x: k * x Taking the following parameters:\n$\\epsilon$ | eps = $10^{-8}$ | 1e-8 x0 = 0.5 idx = 5000 We obtain:\n$f(2) \\approx -17.3998 $ $f(4) \\approx 1.3863$ $g(0.5) \\approx -0.6931$ To consider, the higher value for the iterations and the lower value for $\\epsilon$ (initial pertubations) better success hit in $\\lambda$. And remember there can be false positives, so the more tests your function pass, the more likely you are to get it right.\nFamous Examples Also to conclude my first paper I want to mention some famous maps:\nLogistic Map $$ x_{n+1} = r x_n (1 - x_n) $$ $\\quad x_n \\in (0, 1),\\ r \\in (3.57, 4]$\nHenon Map $$ x_{n+1} = 1 - a x_n^2 + y_n \\\\ y_{n+1} = b x_n $$ $\\quad a = 1.4,\\ b = 0.3$\nLorenz System $$ \\begin{cases} \\dot{x} = \\sigma(y - x) \\\\ \\dot{y} = x(\\rho - z) - y \\\\ \\dot{z} = x y - \\beta z \\end{cases} $$ $\\quad \\text{ with } \\sigma = 10,\\ \\rho = 28,\\ \\beta = \\frac{8}{3}$\nTent Map $$ x_{n+1} = \\begin{cases} \\mu x_n \u0026 \\text{if } x_n \u003c \\frac{1}{2} \\\\ \\mu (1 - x_n) \u0026 \\text{if } x_n \\geq \\frac{1}{2} \\end{cases} $$ $\\quad \\mu \\in (1, 2]$\nIkeda Map $$ \\begin{cases} x_{n+1} = 1 + u (x_n \\cos t_n - y_n \\sin t_n) \\\\ y_{n+1} = u (x_n \\sin t_n + y_n \\cos t_n) \\end{cases} $$ $\\quad t_n = 0.4 - \\dfrac{6}{1 + x_n^2 + y_n^2}$\nPart 2? This was only an introduction to the Chaos Based Encryption and theory, maybe in a future there will be a second part of this post, explaining more tests and checkers of chaotic systems, applying specific attacks into CBE and more!\nFor the moment I recommend you check a little of:\nStrange Attractor Branching diagram (https://espanol.libretexts.org/Matematicas/Computacion_Cientifica_Simulaciones_y_Modelado/Libro%3A_Introducci%C3%B3n_al_Modelado_y_An%C3%A1lisis_de_Sistemas_Complejos_(Sayama)/08%3A_Bifurcaciones) ApEn and SampEn Test of Kolmogorov-Sinai Advanced Permutational Entropy Fractal Dimesion External References [1] https://www.sciencedirect.com/science/article/abs/pii/S002002551200521X\n[2] https://www.mdpi.com/2079-9292/10/12/1392\n[3] https://www.mdpi.com/2073-8994/15/3/726\n[4] https://www.mdpi.com/2073-8994/15/7/1311\n[5] https://www.mdpi.com/2079-9292/11/19/3156\n[6] https://arxiv.org/abs/nlin/0611017\n[7] https://journals.mmupress.com/index.php/jiwe/article/download/1194/684/10872\n[8] https://www.iieta.org/journals/isi/paper/10.18280/isi.250507\n[9] https://hal.science/tel-01179610/document\n[10] https://www.mdpi.com/2073-8994/15/12/2138\n[11] https://www.sciencedirect.com/topics/computer-science/adjacent-pixel\n[12] https://www.researchgate.net/publication/266333755_EMBEDDING_INFORMATION_IN_DCT_COEFFICIENTS_BASED_ON_AVERAGE_COVARIANCE/fulltext/54aea2820cf29661a3d39ee4/EMBEDDING-INFORMATION-IN-DCT-COEFFICIENTS-BASED-ON-AVERAGE-COVARIANCE.pdf\n[13] https://hal.science/hal-02165866v1/document\n[14] https://salil.seas.harvard.edu/sites/g/files/omnuum4266/files/salil/files/acm-publishedversion.pd\n[15] https://link.springer.com/article/10.1007/s11042-018-6824-5\n[16] https://www.sciencedirect.com/science/article/abs/pii/S1007570413005030?via%3Dihub\n[17] https://www.qeios.com/read/K65HZS\n[18] https://medium.com/@rusabhshah17/chaos-based-image-encryption-algorithm-9f4870805a1d\n[19] https://www.researchgate.net/publication/340674341_An_Image_Encryption_Algorithm_Based_on_Random_Walk_and_Hyperchaotic_Systems\n[20] https://espanol.libretexts.org/Matematicas/Computacion_Cientifica_Simulaciones_y_Modelado/Libro%3A_Introducci%C3%B3n_al_Modelado_y_An%C3%A1lisis_de_Sistemas_Complejos_(Sayama)/09%3A_Caos/9.03%3A_Exponente_de_Lyapunov","histogram-analysis#Histogram Analysis":"","local-entropy#Local Entropy":"","npcr--uaci-cryptanalysis#NPCR \u0026amp; UACI Cryptanalysis":"","part-2#Part 2?":"","pixel-correlation-analysis#Pixel Correlation Analysis":"","security-testing-and-image-analysis#Security Testing and Image Analysis":"","understanding-image-functionality#Understanding Image Functionality":""},"title":"Chaos Based Encryption applied to stegoanalysis"},"/blogs/os-internals/":{"data":{"hacking-csgo-aqui#HACKING CSGO AQUI":"HACKING CSGO AQUI"},"title":"Reversing"},"/hardening/":{"data":{"comming-soon#COMMING SOON..":"COMMING SOON.."},"title":"BOOK HARDENINGA"},"/writeups/":{"data":{"":" ℹ️ Note: Some posts are still in progress. Explanations or code may be updated. "},"title":"Writeups done with Caliphal Hounds"},"/writeups/tjctf-2025/":{"data":{"":"","forensicsalbum-cover#forensics/album-cover":"","forensicsdeep-layers#forensics/deep-layers":"","forensicsfootprint#forensics/footprint":"","forensicshidden-message#forensics/hidden-message":"","forensicspacket-palette#forensics/packet-palette":"","forensicsquant#forensics/quant":"","forensicsthats-pietty-cool#forensics/thats-pietty-cool":"\nTJCTF is an international cybersecurity competition hosted by TJCSC, a group of students from Thomas Jefferson High School for Science and Technology in Northern Virginia. The competition consists of a variety of computer science and cybersecurity challenges in an online, jeopardy-style format. You’ll earn points through solving challenges in categories such as binary exploitation, reverse engineering, cryptography, and web. For more information, please join our Discord to learn more about the competition and get notified when the event nears!\nforensics/hidden-message An easy stego challenge where we apply some basics tools to obtain hidden information, in this case is used zsteg to analyze LSB layers and color channel anomalies, extracting hidden data from PNG and BMP images.\nFirst of all, identify the validity of the format with file and later execute zstego.\n$\u003e file suspicious.png suspicious.png: PNG image data, 100 x 100, 8-bit/color RGB, non-interlaced $\u003e zsteg suspicious.png imagedata .. file: Targa image data - Map 1024 x 1023 x 1 +256 +259 \"\\002\\003\" b1,rgb,lsb,xy .. text: \"tjctf{steganography_is_fun}###END###\" b2,g,lsb,xy .. text: [\"U\" repeated 25 times] b2,g,msb,xy .. text: [\"U\" repeated 25 times] b4,g,lsb,xy .. file: 0420 Alliant virtual executable not stripped b4,g,msb,xy .. text: [\"D\" repeated 50 times] b4,bgr,lsb,xy .. file: 0421 Alliant compact executable forensics/deep-layers For this easy challenge zsteg will be reused to detect both, embedded file and base64 text in the image:\n$\u003e file chall.png chall.png: PNG image data, 1 x 1, 8-bit/color RGBA, non-interlaced $\u003e zsteg chall.png [?] 251 bytes of extra data after image end (IEND), offset = 0x77 extradata:0 .. file: Zip archive data, at least v1.0 to extract, compression method=store 00000000: 50 4b 03 04 0a 00 09 00 00 00 41 92 c5 5a 24 fa |PK........A..Z$.| 00000010: 3e e2 43 00 00 00 37 00 00 00 09 00 1c 00 73 65 |\u003e.C...7.......se| 00000020: 63 72 65 74 2e 67 7a 55 54 09 00 03 99 17 42 68 |cret.gzUT.....Bh| 00000030: 99 17 42 68 75 78 0b 00 01 04 f6 01 00 00 04 14 |..Bhux..........| 00000040: 00 00 00 df 0a 4b fa 61 88 12 34 ea 3d 36 f6 0a |.....K.a..4.=6..| 00000050: 47 59 85 43 55 5c 64 ca b6 8f 42 68 0f 7c 94 61 |GY.CU\\d...Bh.|.a| 00000060: 1a 1f 88 38 48 bf f5 96 1b 45 3a 56 dd 7f 1d 44 |...8H....E:V...D| 00000070: 69 54 81 8e 7a f3 94 f2 f0 37 86 37 22 d8 a6 b0 |iT..z....7.7\"...| 00000080: 13 f9 fa 09 61 0a 50 4b 07 08 24 fa 3e e2 43 00 |....a.PK..$.\u003e.C.| 00000090: 00 00 37 00 00 00 50 4b 01 02 1e 03 0a 00 09 00 |..7...PK........| 000000a0: 00 00 41 92 c5 5a 24 fa 3e e2 43 00 00 00 37 00 |..A..Z$.\u003e.C...7.| 000000b0: 00 00 09 00 18 00 00 00 00 00 00 00 00 00 a4 81 |................| 000000c0: 00 00 00 00 73 65 63 72 65 74 2e 67 7a 55 54 05 |....secret.gzUT.| 000000d0: 00 03 99 17 42 68 75 78 0b 00 01 04 f6 01 00 00 |....Bhux........| 000000e0: 04 14 00 00 00 50 4b 05 06 00 00 00 00 01 00 01 |.....PK.........| 000000f0: 00 4f 00 00 00 96 00 00 00 00 00 |.O......... | meta Password .. text: \"cDBseWdsMHRwM3NzdzByZA==\" We could extract the gzip file with some tools such as binwalk, foremost or inclusive zsteg:\nzsteg -E extradata:0 chall.png \u003e hidden.zip Despite it, we can unzip it directly, before that, we base64 decode the “meta Password” section:\n$\u003e echo \"cDBseWdsMHRwM3NzdzByZA==\" | base64 -d p0lygl0tp3ssw0rd With 7z we decompress the content:\n$\u003e 7z x chall.png -pp0lygl0tp3ssw0rd 7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21 p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,8 CPUs Intel(R) Core(TM) i5-1035G1 CPU @ 1.00GHz (706E5),ASM,AES-NI) Scanning the drive for archives: 1 file, 370 bytes (1 KiB) Extracting archive: chall.png -- Path = chall.png Type = zip Offset = 119 Physical Size = 251 Everything is Ok Size: 55 Compressed: 370 $\u003e ls secret.gz \u0026\u0026 gzip -d secret.gz \u0026\u0026 cat secret secret.gz tjctf{p0lygl0t_r3bb1t_h0l3} forensics/footprint We have given a .DS_Store file and they are asking for the flag within a file. Doing the typical strings command we donwon’t find nothing relevant:\n$\u003e strings .DS_Store -n7 | head QIlocblob AIlocblob AIlocblob AIlocblob AIlocblob QIlocblob QIlocblob AIlocblob QIlocblob gIlocblob With a simple Google search, this github tool for MacOS Forensics is appeared: https://github.com/hanwenzhu/.DS_Store-parser, other tools are found but was for server, you could have hosted a webserver with python3, php, or whatever you want to use those tools, but the idea is to simplify the challenge as much as possible, that why we use this tool:\n$\u003e python3 parse.py ../.DS_Store -FumtF3yx-kSP11OD8mFPA Icon location: x 175px, y 46px, 0xffffffffffff0000 0wnNJd_pKKNtfhG-HL8iJw Icon location: x 285px, y 46px, 0xffffffffffff0000 1VmhSaBo9ymK5dUhB3cPEQ Icon location: x 395px, y 46px, 0xffffffffffff0000 1zp7dw6eF3co0VaPDKhUag Icon location: x 505px, y 46px, 0xffffffffffff0000 27bCy1Bt-9nnLG4W8oxkNA Icon location: x 65px, y 270px, 0xffffffffffff0000 ... ... ... Icon location: x 285px, y 1838px, 0xffffffffffff0000 Z3cpkGAUMlLgzQctzCo2Zg Icon location: x 395px, y 1838px, 0xffffffffffff0000 While using the tool we found a lot of files and icons, but not their content, there is when we tryied to decode in base64 the file names, with a simple bash scripting we get the cleartext:\npython3 parse.py ../.DS_Store | grep -v \"Icon location\" | while read i; do echo \"$i\" | base64 -d 2\u003e/dev/null | strings | tr -d '\\n'; done It seems more complex than it is, if you don’t understand it, look at it in detail.\npython3 parse.py ../.DS_Store | grep -v \"Icon location\" | while read i; do \\ echo \"$i\" | \\ base64 -d 2\u003e/dev/null | \\ strings | \\ tr -d '\\n' \\ ;done The output will show the flag splitted in two:\nQ/3fis_useful?} W+#gatjctf{ds_store_ {\\T?L$i~J]{w5Haf@o=UE_}Ex I:P$C:)H9B !`SnwgLx@WrP~(,wf[b Flag: tjctf{ds_store_is_useful?}\nforensics/album-cover Starting with a scanning of the files given:\nAlbumcover.png $\u003e file albumcover.png \u0026\u0026 zsteg albumcover.png albumcover.png: PNG image data, 444 x 441, 8-bit grayscale, non-interlaced b1,r,lsb,xy .. file: AIX core file fulldump b2,r,msb,xy .. text: \"WV[U^UkU\" b4,r,lsb,xy .. file: MPEG ADTS, AAC, v4 Main, 44.1 kHz, stereo+center+LFE b4,rgb,lsb,xy .. text: \"\\\"\\\"\\\"\\\"\\\"\\\"\\\"!\" b4,rgb,msb,xy .. text: [\"w\" repeated 9 times] enc.py import wave from PIL import Image import numpy as np #sample_rate = 44100 with wave.open('flag.wav', 'rb') as w: frames = np.frombuffer(w.readframes(w.getnframes()), dtype=np.int16) print(w.getnframes()) sampwidth = w.getsampwidth() # 2 nchannels = w.getnchannels() # 1 w.close() arr = np.array(frames) img = arr.reshape((441, 444)) img = (img + 32767) / 65535 * 255 img = img.astype(np.uint8) img = Image.fromarray(img) img = img.convert('L') img.save('albumcover.png') At first glance, it seems to be encode a wav file into a png, following a linear map, encoding each 16-bit knowing: $s \\in [-32768, 32767]$ $$ \\text{pixel} = \\frac{s + 32767}{65535} \\times 255 $$\nIf we invert it:\n$$ s = \\frac{\\text{pixel}}{255} \\times 65535 - 32767 $$\nNow opening a new wav file in write mode, set mono, 16-bit (round s to the nearest integer) and 44.1 kHz, you will obtain the original wav:\nimport wave import numpy as np from PIL import Image # --- Configuration: must match your original WAV --- OUTPUT_WAV = 'recovered.wav' INPUT_PNG = 'albumcover.png' SAMPLE_RATE = 44100 # Hz N_CHANNELS = 1 SAMPLE_WIDTH = 2 # bytes (16-bit) IMG_WIDTH = 444 # as in your encoder IMG_HEIGHT = 441 # as in your encoder # ----------------------------------------------- # 1) Load the image and convert to a numpy array img = Image.open(INPUT_PNG).convert('L') arr8 = np.array(img, dtype=np.uint8) # 2) Reverse the scaling: # original: img = (samples + 32767) / 65535 * 255 # so: samples = img/255*65535 - 32767 arr16 = (arr8.astype(np.float32) / 255.0 * 65535.0) - 32767.0 # 3) Round and cast back to int16 samples = np.round(arr16).astype(np.int16) # 4) Flatten to 1D PCM stream pcm = samples.reshape(-1) # 5) Write to a new WAV file with wave.open(OUTPUT_WAV, 'wb') as w: w.setnchannels(N_CHANNELS) w.setsampwidth(SAMPLE_WIDTH) w.setframerate(SAMPLE_RATE) w.writeframes(pcm.tobytes()) print(f\"Reconstructed WAV written to {OUTPUT_WAV} ({pcm.shape[0]} frames)\") Since the audio is unreadable, we open it in a visualizer like Sonic Visualizer, inside the Spectogram, we found the flag written:\nforensics/packet-palette Inside the pcap we can find a png embeded, with a fast visualization:\nFrom here, we will the padding before PNG and with tshark create a little script to obtain the image:\n5553424900??0015000001f4\nThus, the following command is created:\ntshark -r chall.pcapng -T fields -e data | grep \"5553424900\" | sed -E 's/5553424900[0-9a-z]{2}0015000001f4//g' | xxd -r -p \u003e flag.png Basicly, we get the content of the payload from the tcp packet (also can be done as: -e tcp.payload), filter to the content with the correct padding, delete the padding with some regex formula, and later convert it into a image:\nforensics/quant Now we are getting hotter, only 54 solves, approximately 100 fewer resolutions than the previous ones. This challenge is very curious, a new functionality of images found, furthermore finally, a tool such as zsteg for jpg/jpeg images: jsteg.\nFor the begging, use the new discovered tool, to get nothing about the image haha:\n$\u003e jsteg reveal lost.jpg out jpeg does not contain hidden data After some basics scanning we didn’t found nothing interesting, so we dedice to grab a random jpeg image and compare to the actual to identify faster any suspicious hexadecimal pattern.\nIn a fast way, we conclude the headers of the image were corrupt:\n$\u003e xxd goodImage.jpg | head 00000000: ffd8 ffdb 0043 0004 0303 0403 0304 0403 .....C.......... 00000010: 0405 0404 0506 0a07 0606 0606 0d09 0a08 ................ 00000020: 0a0f 0d10 100f 0d0f 0e11 1318 1411 1217 ................ 00000030: 120e 0f15 1c15 1719 191b 1b1b 1014 1d1f ................ 00000040: 1d1a 1f18 1a1b 1aff db00 4301 0405 0506 ..........C..... 00000050: 0506 0c07 070c 1a11 0f11 1a1a 1a1a 1a1a ................ 00000060: 1a1a 1a1a 1a1a 1a1a 1a1a 1a1a 1a1a 1a1a ................ 00000070: 1a1a 1a1a 1a1a 1a1a 1a1a 1a1a 1a1a 1a1a ................ 00000080: 1a1a 1a1a 1a1a 1a1a 1a1a 1a1a ffc0 0011 ................ 00000090: 0801 2100 fa03 0122 0002 1101 0311 01ff ..!....\"........ $\u003e xxd lost.jpg | head 00000000: ffd8 ffe0 0010 4a46 4946 0001 0101 0090 ......JFIF...... 00000010: 0090 0000 ffdb 0043 0000 0000 0000 0000 .......C........ 00000020: 0000 0000 0000 0000 0000 0000 0000 0000 ................ 00000030: 0000 0000 0000 0000 0000 0000 0000 0000 ................ 00000040: 0000 0000 0000 0000 0000 0000 0000 0000 ................ 00000050: 0000 0000 0000 0000 00ff db00 4301 0000 ............C... 00000060: 0000 0000 0000 0000 0000 0000 0000 0000 ................ 00000070: 0000 0000 0000 0000 0000 0000 0000 0000 ................ 00000080: 0000 0000 0000 0000 0000 0000 0000 0000 ................ 00000090: 0000 0000 0000 0000 0000 0000 000c ffc0 ................ In turn of being called magic numbers/headers, it is also called Quantifying Tables, with our prompt engieneering and scripting skills we created the following Quantifying tables changer:\n#!/usr/bin/env python3 import sys LUMA_QT = [ 16, 11, 10, 16, 24, 40, 51, 61, 12, 12, 14, 19, 26, 58, 60, 55, 14, 13, 16, 24, 40, 57, 69, 56, 14, 17, 22, 29, 51, 87, 80, 62, 18, 22, 37, 56, 68, 109, 103, 77, 24, 35, 55, 64, 81, 104, 113, 92, 49, 64, 78, 87,103, 121, 120, 101, 72, 92, 95, 98,112, 100, 103, 99, ] CHROMA_QT = [ 17, 18, 24, 47, 99, 99, 99, 99, 18, 21, 26, 66, 99, 99, 99, 99, 24, 26, 56, 99, 99, 99, 99, 99, 47, 66, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, ] def build_dqt_segment(table, tid): \"\"\"Construct a DQT segment for an 8-bit table.\"\"\" # ID byte: (prec=0)\u003c\u003c4 | tid header = bytes([0xFF, 0xDB, 0x00, 0x43, tid]) body = bytes(table) return header + body def patch_qtables(infile, outfile): with open(infile, 'rb') as f: data = f.read() out = bytearray() offset = 0 # 1) Copy up to the first DQT idx = data.find(b'\\xFF\\xDB', offset) if idx == -1: raise RuntimeError(\"No encuentro ningún DQT en el JPEG original.\") out += data[:idx] offset = idx # 2) Skips all original DQTs while True: if data[offset:offset+2] != b'\\xFF\\xDB': break length = int.from_bytes(data[offset+2:offset+4], 'big') offset += 2 + length # 3) Insert our tables out += build_dqt_segment(LUMA_QT, 0) out += build_dqt_segment(CHROMA_QT, 1) # 4) Add the rest of the file (from where we skipped the old DQT) out += data[offset:] # 5) Save the patched JPEG with open(outfile, 'wb') as f: f.write(out) print(f\"JPEG corregido escrito en {outfile}\") if __name__ == '__main__': if len(sys.argv) != 3: print(f\"Uso: {sys.argv[0]} input.jpg output.jpg\") sys.exit(1) patch_qtables(sys.argv[1], sys.argv[2]) By applying it, the flag will appear with a low resolution but human redeable:\nAnyways, I recommend you read some of this blogs to understand more how jpeg/jpg works and can be able to apply this knownledge in future challenges:\nhttps://compress-or-die.com/JPG-verstehen https://en.wikipedia.org/wiki/JPEG forensics/thats-pietty-cool Lower and lower, I love this, for this challenge we have the following image, without any suspicious information that we can take a look:\nAre you able to see something? I used to stegoveritas to get a closer look into the image layers, RGB specially, in this case I used it to see better those little dots from the image, this tool in this case, is not necesary.\nRaw image: Stegoveritas images: I wanted to see is that was part of the real image or not, in google I found the real image and not, https://commons.wikimedia.org/wiki/File:Tableau_I,_by_Piet_Mondriaan.jpg, also from a jpg to a png? Interesting…\nTaking a closer look, with paint, I calculate the padding of each pixels and where they appear:\nThe dotted pixels started in (0,0) in plane xy and stopped in x=1845 and y=1000, being the last pixel: (1845,1000), knowing this I have created the following image extractor:\nfrom PIL import Image, ImageDraw img = Image.open(\"runme.png\") pixels = img.load() width, height = img.size x_padding = 15 y_padding = 100 pixelArray = [] for y in range(0, height, y_padding): if y \u003e 1000: break row = [] for x in range(0,width, x_padding): if x \u003e 1845: break row.append(pixels[x, y]) pixelArray.append(row) # Creating new image bigPixel = 50 width = len(pixelArray[0]) * bigPixel height = len(pixelArray) * bigPixel img = Image.new(\"RGB\", (width, height), color=(255, 255, 255)) draw = ImageDraw.Draw(img) for row_idx, row in enumerate(pixelArray): for col_idx, color in enumerate(row): x0 = col_idx * bigPixel y0 = row_idx * bigPixel x1 = x0 + bigPixel y1 = y0 + bigPixel draw.rectangle([x0, y0, x1, y1], fill=color) img.save(\"flag.png\") Recieving the image above it started searching how to run an image haha, and I found, with a little help from the challenge name, and esoteric language called: piet\nWith the following webpage I obtained the flag: https://gabriellesc.github.io/piet/"},"title":"TJCTF 2025 | 7/8 Forensics challenges"}}